{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "### Use text preprocessing steps of toy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Necessary libraries for performing text preprocessing tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jamshaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jamshaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "# \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Displaying Data from an Excel File Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>TL;DR: I wish to ask out my longtime friend th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I’m going to kill myself. I can’t take this an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I don’t know how to make him leave because he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The contract with Apex is over and they screwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>I have a fear of fainting so I was like “what ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Hey there r/assistance, Not sure if this is th...\n",
       "1    This is helping to get kids in the area tan ab...\n",
       "2    According to [a study from <url> and its subje...\n",
       "3    Okay, So in since October have just got out of...\n",
       "4    I'm just blown away by this doctor's willingne...\n",
       "..                                                 ...\n",
       "995  TL;DR: I wish to ask out my longtime friend th...\n",
       "996  I’m going to kill myself. I can’t take this an...\n",
       "997  I don’t know how to make him leave because he ...\n",
       "998  The contract with Apex is over and they screwe...\n",
       "999  I have a fear of fainting so I was like “what ...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_excel('text_preprocessing_toy_dataset.xlsx')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      hey there r/assistance, not sure if this is th...\n",
       "1      this is helping to get kids in the area tan ab...\n",
       "2      according to [a study from <url> and its subje...\n",
       "3      okay, so in since october have just got out of...\n",
       "4      i'm just blown away by this doctor's willingne...\n",
       "                             ...                        \n",
       "995    tl;dr: i wish to ask out my longtime friend th...\n",
       "996    i’m going to kill myself. i can’t take this an...\n",
       "997    i don’t know how to make him leave because he ...\n",
       "998    the contract with apex is over and they screwe...\n",
       "999    i have a fear of fainting so i was like “what ...\n",
       "Name: lower_case, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts all characters in each string to lowercase.\n",
    "\n",
    "\n",
    "df['lower_case'] = df['text'].str.lower()        # str is the part of the pandas library.\n",
    "df['lower_case']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hey there r/assistance, Not sure if this is th...   \n",
       "1  This is helping to get kids in the area tan ab...   \n",
       "2  According to [a study from <url> and its subje...   \n",
       "3  Okay, So in since October have just got out of...   \n",
       "4  I'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                         punctuation  \n",
       "0  hey there r/assistance, not sure if this is th...  \n",
       "1  this is helping to get kids in the area tan ab...  \n",
       "2  according to [a study from <url> and its subje...  \n",
       "3  okay, so in since october have just got out of...  \n",
       "4  i'm just blown away by this doctor's willingne...  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punctuation'] = df['lower_case'].str.replace('[^\\w\\s]', '')  # to replace all non-word characters (\\w) and non-whitespace characters (\\s) with an empty string\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove special characters\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s\\d½]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>special_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hey there r/assistance, Not sure if this is th...   \n",
       "1  This is helping to get kids in the area tan ab...   \n",
       "2  According to [a study from <url> and its subje...   \n",
       "3  Okay, So in since October have just got out of...   \n",
       "4  I'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                  special_characters  \n",
       "0  hey there rassistance not sure if this is the ...  \n",
       "1  this is helping to get kids in the area tan ab...  \n",
       "2  according to a study from url and its subjects...  \n",
       "3  okay so in since october have just got out of ...  \n",
       "4  im just blown away by this doctors willingness...  "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['special_characters'] = df['punctuation'].apply(remove_special_characters)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove emojis\n",
    "#def remove_emojis(text):\n",
    "    #return re.sub(r'[^\\w\\s\\d]', '', text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['remove emojis'] = df['special_characters'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert_emoji_to_meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is ::smiling_face_with_smiling_eyes::\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Python is :😊:')) # emojize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def convert_emoji_to_meaning(text):\n",
    "    return emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emoji to mean']= df['special_characters'].apply(convert_emoji_to_meaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitespace Normalization\n",
    "\n",
    "def whitespace_normalization(text):\n",
    "    text = re.sub('[\\s]+', ' ', text).strip()  # [\\s] WHITE SPACE CHAR + MEAN EITHER IT COME 1 OR 3 TIMES\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>special_characters</th>\n",
       "      <th>emoji to mean</th>\n",
       "      <th>white space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hey there r/assistance, Not sure if this is th...   \n",
       "1  This is helping to get kids in the area tan ab...   \n",
       "2  According to [a study from <url> and its subje...   \n",
       "3  Okay, So in since October have just got out of...   \n",
       "4  I'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                  special_characters  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                       emoji to mean  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                         white space  \n",
       "0  hey there rassistance not sure if this is the ...  \n",
       "1  this is helping to get kids in the area tan ab...  \n",
       "2  according to a study from url and its subjects...  \n",
       "3  okay so in since october have just got out of ...  \n",
       "4  im just blown away by this doctors willingness...  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['white space'] = df['emoji to mean'].apply(whitespace_normalization)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['remove emojis'].to_excel(r'D:\\Ai course\\NAVTTAC Code\\Text_Preprocessing_Toy_Dataset.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>special_characters</th>\n",
       "      <th>emoji to mean</th>\n",
       "      <th>white space</th>\n",
       "      <th>stop words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey rassistance sure right place post goes im ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im blown away doctors willingness help feel va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hey there r/assistance, Not sure if this is th...   \n",
       "1  This is helping to get kids in the area tan ab...   \n",
       "2  According to [a study from <url> and its subje...   \n",
       "3  Okay, So in since October have just got out of...   \n",
       "4  I'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                  special_characters  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                       emoji to mean  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                         white space  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                          stop words  \n",
       "0  hey rassistance sure right place post goes im ...  \n",
       "1  helping get kids area tan ability practice str...  \n",
       "2  according study url subjects major risk factor...  \n",
       "3  okay since october got eight year relationship...  \n",
       "4  im blown away doctors willingness help feel va...  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stop words']= df['white space'].apply (lambda x: \" \".join(word for word in x.split()  if word not in stop_words))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "def apply_contraction(text):\n",
    "    \n",
    "    return contractions.fix(text, slang = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>special_characters</th>\n",
       "      <th>emoji to mean</th>\n",
       "      <th>white space</th>\n",
       "      <th>stop words</th>\n",
       "      <th>contractions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey rassistance sure right place post goes im ...</td>\n",
       "      <td>hey rassistance sure right place post goes i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im blown away doctors willingness help feel va...</td>\n",
       "      <td>i am blown away doctors willingness help feel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hey there r/assistance, Not sure if this is th...   \n",
       "1  This is helping to get kids in the area tan ab...   \n",
       "2  According to [a study from <url> and its subje...   \n",
       "3  Okay, So in since October have just got out of...   \n",
       "4  I'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                  special_characters  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                       emoji to mean  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                         white space  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                          stop words  \\\n",
       "0  hey rassistance sure right place post goes im ...   \n",
       "1  helping get kids area tan ability practice str...   \n",
       "2  according study url subjects major risk factor...   \n",
       "3  okay since october got eight year relationship...   \n",
       "4  im blown away doctors willingness help feel va...   \n",
       "\n",
       "                                        contractions  \n",
       "0  hey rassistance sure right place post goes i a...  \n",
       "1  helping get kids area tan ability practice str...  \n",
       "2  according study url subjects major risk factor...  \n",
       "3  okay since october got eight year relationship...  \n",
       "4  i am blown away doctors willingness help feel ...  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['contractions'] = df['stop words'].apply(apply_contraction)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove_repetitive_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>special_characters</th>\n",
       "      <th>emoji to mean</th>\n",
       "      <th>white space</th>\n",
       "      <th>stop words</th>\n",
       "      <th>contractions</th>\n",
       "      <th>repetitive_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey rassistance sure right place post goes im ...</td>\n",
       "      <td>hey rassistance sure right place post goes i a...</td>\n",
       "      <td>hey rassistance sure right place post goes i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im blown away doctors willingness help feel va...</td>\n",
       "      <td>i am blown away doctors willingness help feel ...</td>\n",
       "      <td>i am blown away doctors willingness help feel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hey there r/assistance, Not sure if this is th...   \n",
       "1  This is helping to get kids in the area tan ab...   \n",
       "2  According to [a study from <url> and its subje...   \n",
       "3  Okay, So in since October have just got out of...   \n",
       "4  I'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                  special_characters  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                       emoji to mean  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                         white space  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                          stop words  \\\n",
       "0  hey rassistance sure right place post goes im ...   \n",
       "1  helping get kids area tan ability practice str...   \n",
       "2  according study url subjects major risk factor...   \n",
       "3  okay since october got eight year relationship...   \n",
       "4  im blown away doctors willingness help feel va...   \n",
       "\n",
       "                                        contractions  \\\n",
       "0  hey rassistance sure right place post goes i a...   \n",
       "1  helping get kids area tan ability practice str...   \n",
       "2  according study url subjects major risk factor...   \n",
       "3  okay since october got eight year relationship...   \n",
       "4  i am blown away doctors willingness help feel ...   \n",
       "\n",
       "                                     repetitive_char  \n",
       "0  hey rassistance sure right place post goes i a...  \n",
       "1  helping get kids area tan ability practice str...  \n",
       "2  according study url subjects major risk factor...  \n",
       "3  okay since october got eight year relationship...  \n",
       "4  i am blown away doctors willingness help feel ...  "
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove same char\n",
    "def repetative_char(text):\n",
    "    return re.sub(r'\\b\\w*(\\w)\\1{3,}\\w*\\b', '',text).strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['repetitive_char']= df['contractions'].apply(repetative_char)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_num(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "df['repetitive_char'] = df['repetitive_char'].apply(remove_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>punctuation</th>\n",
       "      <th>special_characters</th>\n",
       "      <th>emoji to mean</th>\n",
       "      <th>white space</th>\n",
       "      <th>stop words</th>\n",
       "      <th>contractions</th>\n",
       "      <th>repetitive_char</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there r/assistance, not sure if this is th...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey there rassistance not sure if this is the ...</td>\n",
       "      <td>hey rassistance sure right place post goes im ...</td>\n",
       "      <td>hey rassistance sure right place post goes i a...</td>\n",
       "      <td>hey rassistance sure right place post goes i a...</td>\n",
       "      <td>hey rassistance sure right place post go i am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>this is helping to get kids in the area tan ab...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "      <td>helping get kids area tan ability practice str...</td>\n",
       "      <td>helping get kid area tan ability practice stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to [a study from &lt;url&gt; and its subje...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according to a study from url and its subjects...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "      <td>according study url subjects major risk factor...</td>\n",
       "      <td>according study url subject major risk factor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Okay, So in since October have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay, so in since october have just got out of...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay so in since october have just got out of ...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "      <td>okay since october got eight year relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>i'm just blown away by this doctor's willingne...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im just blown away by this doctors willingness...</td>\n",
       "      <td>im blown away doctors willingness help feel va...</td>\n",
       "      <td>i am blown away doctors willingness help feel ...</td>\n",
       "      <td>i am blown away doctors willingness help feel ...</td>\n",
       "      <td>i am blown away doctor willingness help feel v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Hey there r/assistance, Not sure if this is th...   \n",
       "1  This is helping to get kids in the area tan ab...   \n",
       "2  According to [a study from <url> and its subje...   \n",
       "3  Okay, So in since October have just got out of...   \n",
       "4  I'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                         punctuation  \\\n",
       "0  hey there r/assistance, not sure if this is th...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to [a study from <url> and its subje...   \n",
       "3  okay, so in since october have just got out of...   \n",
       "4  i'm just blown away by this doctor's willingne...   \n",
       "\n",
       "                                  special_characters  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                       emoji to mean  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                         white space  \\\n",
       "0  hey there rassistance not sure if this is the ...   \n",
       "1  this is helping to get kids in the area tan ab...   \n",
       "2  according to a study from url and its subjects...   \n",
       "3  okay so in since october have just got out of ...   \n",
       "4  im just blown away by this doctors willingness...   \n",
       "\n",
       "                                          stop words  \\\n",
       "0  hey rassistance sure right place post goes im ...   \n",
       "1  helping get kids area tan ability practice str...   \n",
       "2  according study url subjects major risk factor...   \n",
       "3  okay since october got eight year relationship...   \n",
       "4  im blown away doctors willingness help feel va...   \n",
       "\n",
       "                                        contractions  \\\n",
       "0  hey rassistance sure right place post goes i a...   \n",
       "1  helping get kids area tan ability practice str...   \n",
       "2  according study url subjects major risk factor...   \n",
       "3  okay since october got eight year relationship...   \n",
       "4  i am blown away doctors willingness help feel ...   \n",
       "\n",
       "                                     repetitive_char  \\\n",
       "0  hey rassistance sure right place post goes i a...   \n",
       "1  helping get kids area tan ability practice str...   \n",
       "2  according study url subjects major risk factor...   \n",
       "3  okay since october got eight year relationship...   \n",
       "4  i am blown away doctors willingness help feel ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  hey rassistance sure right place post go i am ...  \n",
       "1  helping get kid area tan ability practice stro...  \n",
       "2  according study url subject major risk factor ...  \n",
       "3  okay since october got eight year relationship...  \n",
       "4  i am blown away doctor willingness help feel v...  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "df['clean_text'] = df['repetitive_char'].apply(lambda x: \" \".join(Word(word).lemmatize() for word in x.split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lematizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    lematized_tokens = \" \".join([lematizer.lemmatize(token,pos = 'v')for token in tokens])\n",
    "\n",
    "    return lematized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      hey rassistance sure right place post go i be ...\n",
      "1      help get kid area tan ability practice strong ...\n",
      "2      accord study url subject major risk factor fam...\n",
      "3      okay since october get eight year relationship...\n",
      "4      i be blow away doctor willingness help feel va...\n",
      "                             ...                        \n",
      "995    tldr wish ask longtime friend valentine afraid...\n",
      "996    i be go kill can not take anymore much fuck be...\n",
      "997    do not know make leave say go dispute charge e...\n",
      "998    contract apex screw hard do not another job li...\n",
      "999    fear faint like faint much fear test next thin...\n",
      "Name: stemming, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['stemming'] = df['clean_text'].apply(stemming)\n",
    "print(df['stemming'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all other words which is still present in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garbage_text(text):\n",
    "        pattern = r'(1x200b|x200b| x x200b|x 200b)'\n",
    "\n",
    "        clean_text = re.sub(pattern, '', text)\n",
    "    \n",
    "        return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      hey rassistance sure right place post go i be ...\n",
       "1      help get kid area tan ability practice strong ...\n",
       "2      accord study url subject major risk factor fam...\n",
       "3      okay since october get eight year relationship...\n",
       "4      i be blow away doctor willingness help feel va...\n",
       "                             ...                        \n",
       "995    tldr wish ask longtime friend valentine afraid...\n",
       "996    i be go kill can not take anymore much fuck be...\n",
       "997    do not know make leave say go dispute charge e...\n",
       "998    contract apex screw hard do not another job li...\n",
       "999    fear faint like faint much fear test next thin...\n",
       "Name: stemming, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemming'].apply(garbage_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "im         709\n",
       "like       416\n",
       "feel       344\n",
       "dont       342\n",
       "know       299\n",
       "get        273\n",
       "ive        256\n",
       "time       248\n",
       "really     246\n",
       "would      232\n",
       "even       207\n",
       "want       201\n",
       "cant       196\n",
       "one        183\n",
       "go         180\n",
       "people     179\n",
       "going      178\n",
       "help       176\n",
       "much       160\n",
       "anxiety    152\n",
       "life       146\n",
       "things     143\n",
       "years      139\n",
       "also       138\n",
       "back       135\n",
       "day        134\n",
       "work       132\n",
       "think      123\n",
       "got        122\n",
       "need       120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(\" \".join (df['stop words']).split()).value_counts()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more_stop_words = ['one', 'ive', 'im']\n",
    "\n",
    "df['stemming'].to_excel(r'D:\\Ai course\\NAVTTAC Code\\cleantext.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['contractions'].apply(lambda x : \" \".join(word for word in x.split if word not in stop_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
